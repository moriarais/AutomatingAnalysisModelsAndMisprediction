{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Machine learning library\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing configuration\n",
    "class Location:\n",
    "    \"\"\"Specify the locations of inputs and outputs\"\"\"\n",
    "\n",
    "    # Get the path of the directory containing the script file\n",
    "    script_dir = os.path.dirname(os.path.abspath(sys.path[0]))\n",
    "\n",
    "    # Navigate up to the top-level directory\n",
    "    src_level_dir = os.path.dirname(script_dir)\n",
    "\n",
    "    top_level_dir = os.path.dirname(src_level_dir)\n",
    "\n",
    "    # Define the relative path to the data directory\n",
    "    data_dir = os.path.join(top_level_dir, \"AutomatingAnalysisModelsAndMisprediction\\\\data\")\n",
    "\n",
    "    data_raw: str = f\"{data_dir}\\\\raw\\\\customer_churn.csv\"\n",
    "    data_csv_process: str = f\"{data_dir}\\\\processed\\\\customer_churn.csv\"\n",
    "    data_process: str = f\"{data_dir}\\\\processed\\\\customer_churn.pkl\"\n",
    "    \n",
    "    \n",
    "class ProcessConfig:\n",
    "    \"\"\"Specify the parameters of the `process` flow\"\"\"\n",
    "\n",
    "    label: str = \"Churn\"\n",
    "    test_size: float = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing functions\n",
    "def getProcessedData(file_path: str):\n",
    "    # read python dict back from the file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        split_dict = pickle.load(f)\n",
    "\n",
    "    X_train = split_dict[\"X_train\"]\n",
    "    X_test = split_dict[\"X_test\"]\n",
    "    y_train = split_dict[\"y_train\"]\n",
    "    y_test = split_dict[\"y_test\"]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def getCSVData(url: str):\n",
    "    data = pd.read_csv(url)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csv processed data\n",
    "dataset = getCSVData(Location.data_csv_process)\n",
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "X_train, X_test, Y_train, Y_test = getProcessedData(Location.data_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features. Require for Machine learning\n",
    "sc = StandardScaler()\n",
    "# Fit to data, then transform it\n",
    "X_train = sc.fit_transform(X_train)\n",
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standardization by centering and scaling\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init an H2O cluster\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to H2OFrame\n",
    "# the train result will be used to train a machine learning model\n",
    "train = h2o.H2OFrame(np.concatenate((X_train, Y_train.values.reshape(-1, 1)), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = list(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify target variable and predictor variables\n",
    "x = train.drop(ProcessConfig.label, axis=1).columns\n",
    "y = ProcessConfig.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run H2O AutoML to automatically select, train and optimize SVM model\n",
    "aml = H2OAutoML(max_models=10, sort_metric='mse', max_runtime_secs=5 * 60, seed=666)\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the leaderboard of trained models\n",
    "lb = aml.leaderboard\n",
    "print(lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model to predict on test data\n",
    "model = aml.leader\n",
    "X_h2o = h2o.H2OFrame(X_test)\n",
    "X_h2o.columns = list(dataset.columns)[:-1]\n",
    "y_pred = model.predict(X_h2o).as_data_frame().values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a PySVM SVM model\n",
    "model = LinearSVC(random_state=0, tol=1e-5, max_iter=10000, dual=False)\n",
    "Y_pred = model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,5))\n",
    "# sns.scatterplot(Y_pred, y[ProcessConfig.label] ,ax=ax)\n",
    "# sns.lineplot(Y_pred,Y_pred,ax=ax,color='black')\n",
    "# ax.set_xlabel(ProcessConfig.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "misclassified = np.where(Y_test != y_pred)[0]\n",
    "print(\"Indices of potentially misclassified instances: \", misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix - summarizing the performance of a classification algorithm.\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xticks([0, 1], [\"Negative\", \"Positive\"])\n",
    "plt.yticks([0, 1], [\"Negative\", \"Positive\"])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic (ROC)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
